{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# HTML Parser\n",
    "Use this as a lab for testing how to parse various HTML pages or API returns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import json\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "\n",
    "import shelfy.models.scraper"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Google parse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "url = 'https://www.google.com/search?q=amazon+book+' + isbn\n",
    "\n",
    "\n",
    "ua = {'User-Agent': 'Mozilla/5.0 (Macintosh; Intel Mac OS X 10_8_2) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/27.0.1453.116 Safari/537.36'}                                                                \n",
    "\n",
    "response = requests.get(url, headers=ua)\n",
    "content = response.content\n",
    "\n",
    "# Parse for amazon link\n",
    "soup = BeautifulSoup(content, 'html.parser')\n",
    "\n",
    "for link in soup.find_all('a'):\n",
    "    url = str(link.get('href'))\n",
    "    if 'www.amazon.com' in url:\n",
    "        print(url)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Amazon parse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "isbn = '1617290238'\n",
    "google_search_url = shelfy.models.scraper.get_google_search_url_from_query(isbn)\n",
    "link = shelfy.models.scraper.get_amazon_url_from_google_search(google_search_url)\n",
    "\n",
    "print(link)\n",
    "\n",
    "ua = {'User-Agent': 'Mozilla/5.0 (Macintosh; Intel Mac OS X 10_8_2) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/27.0.1453.116 Safari/537.36'}                                                                \n",
    "\n",
    "response = requests.get(link, headers=ua)\n",
    "content = response.content\n",
    "\n",
    "\n",
    "\n",
    "# Parse for amazon link\n",
    "soup = BeautifulSoup(content, 'html.parser')\n",
    "\n",
    "\n",
    "print(soup)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(soup.find_all(id = 'productTitle'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Title\n",
    "try:\n",
    "    #print(soup.find_all(id='productTitle'))\n",
    "    title = soup.find_all(id='productTitle')[0].contents[0]\n",
    "    print(title)\n",
    "except:\n",
    "    print(\"couldn't find title\")\n",
    "\n",
    "    \n",
    "    \n",
    "    \n",
    "# Author\n",
    "try:\n",
    "    author = soup.find_all(class_ = 'a-link-normal contributorNameID')[0].contents[0]\n",
    "    print(author)\n",
    "except:\n",
    "    print(\"couldn't find title\")\n",
    "    \n",
    "    \n",
    "# ISBN-10\n",
    "try:\n",
    "    book_details = soup.findAll(id = 'detail-bullets')\n",
    "    \n",
    "    for line in str(book_details[0]).split('\\n'):\n",
    "        if 'ISBN-10' in line:\n",
    "            print(line[20:30])\n",
    "        \n",
    "    #print(str(book_details[0]).split('\\n'))\n",
    "    \n",
    "    #print(str(book_details).split('\\n'))\n",
    "except:\n",
    "    print(\"couldn't find isbn 13\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Google books"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "print(str(soup).find('\\section'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "string[i1:i2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ua = {'User-Agent': 'Mozilla/5.0 (Macintosh; Intel Mac OS X 10_8_2) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/27.0.1453.116 Safari/537.36'}\n",
    "\n",
    "google_books_api_key = 'AIzaSyBueagspvDe8R-prJ3bmqtEnr7fPTH10Xo'\n",
    "\n",
    "isbn_10 = '0387848576'\n",
    "\n",
    "\n",
    "rest_url = 'https://www.googleapis.com/books/v1/volumes?key='+google_books_api_key+'&q=isbn:' + isbn_10\n",
    "response = requests.get(rest_url, headers=ua)\n",
    "\n",
    "\n",
    "content = json.loads(response.content)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "print(content)\n",
    "\n",
    "\n",
    "\n",
    "# Get title\n",
    "print(content['items'][0]['volumeInfo']['title'])\n",
    "\n",
    "# Get authors\n",
    "print(content['items'][0]['volumeInfo']['authors'])\n",
    "\n",
    "# Get publisher\n",
    "print(content['items'][0]['volumeInfo']['publisher'])\n",
    "\n",
    "\n",
    "# Get isbn-10\n",
    "print(content['items'][0]['volumeInfo']['industryIdentifiers'][1]['identifier'])\n",
    "\n",
    "\n",
    "# Get isbn-13\n",
    "print(content['items'][0]['volumeInfo']['industryIdentifiers'][0]['identifier'])\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import IPython\n",
    "IPython.display.Audio(shelfy.SHELFY_BASE_PATH + 'beep.mp3')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Good reads"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ISBN to goodreads id\n",
    "\n",
    "ua = {'User-Agent': 'Mozilla/5.0 (Macintosh; Intel Mac OS X 10_8_2) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/27.0.1453.116 Safari/537.36'}\n",
    "\n",
    "\n",
    "isbn = '1449393632'\n",
    "\n",
    "rest_url = 'https://www.goodreads.com/book/show.xml?key=ooiawV83knPQnQ8If3eiSg&isbn=' + isbn\n",
    "response = requests.get(rest_url, headers=ua)\n",
    "soup = BeautifulSoup(response.content, 'lxml')\n",
    "id = soup.find('id').contents[0]\n",
    "\n",
    "print(id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Goodreads ID to info\n",
    "\n",
    "rest_url = 'https://www.goodreads.com/book/show.xml?key=ooiawV83knPQnQ8If3eiSg&id='+id\n",
    "\n",
    "response = requests.get(rest_url, headers=ua)\n",
    "\n",
    "soup = BeautifulSoup(response.content, 'lxml')\n",
    "\n",
    "print(soup)\n",
    "\n",
    "# Title\n",
    "#print(soup.title.contents[0])\n",
    "\n",
    "\n",
    "# Authors\n",
    "#print([child.find('name').contents for child in soup.authors.children])\n",
    "print([child.find('name').contents[0] for child in soup.authors.children if child.find('name') != -1])\n",
    "\n",
    "# Publisher\n",
    "print(soup.find('publisher').contents[0])\n",
    "\n",
    "\n",
    "\n",
    "# ISBN 10\n",
    "\n",
    "\n",
    "\n",
    "# ISBN 13"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Amazon product"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import bottlenose\n",
    "\n",
    "\n",
    "AWS_ASSOCIATE_TAG = 'prestonh-20'\n",
    "\n",
    "isbn = \"0553582011\"\n",
    "\n",
    "\n",
    "def get_amazon_object():\n",
    "    amazon = bottlenose.Amazon(AWS_ACCESS_KEY_ID, AWS_SECRET_ACCESS_KEY, AWS_ASSOCIATE_TAG)\n",
    "    return amazon\n",
    "\n",
    "amazon = get_amazon_object()\n",
    "\n",
    "\n",
    "def get_first_sales_url(isbn, amazon):\n",
    "    response = amazon.ItemLookup(ItemId=isbn, ResponseGroup=\"Small\",\n",
    "    SearchIndex=\"Books\", IdType=\"ISBN\").decode('utf-8')\n",
    "    \n",
    "    \n",
    "    soup = BeautifulSoup(str(response), 'xml')\n",
    "    \n",
    "    item_links = soup.Items.Item.ItemLinks.find_all('ItemLink')\n",
    "    \n",
    "    for item_link in item_links:\n",
    "        description = item_link.Description.text\n",
    "        \n",
    "        if description == 'All Offers':\n",
    "            return item_link.URL.text\n",
    "\n",
    "    \n",
    "\n",
    "        \n",
    "url = get_first_sales_url(isbn, amazon)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "import shelfy.models.scraper"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_next_sales_url_from_amazon(soup, base_url):\n",
    "    '''\n",
    "    Given a url to a sales page, returns the next available sales page\n",
    "    if it exists, otherwise returns None\n",
    "    '''\n",
    "    \n",
    "    try:\n",
    "        # There is a next button; get the url for it\n",
    "        next_url = soup.find(class_='a-last').a['href']\n",
    "    except:\n",
    "        # Failed because no next link to follow; return None!\n",
    "        return None\n",
    "\n",
    "    # Append all the stuff before\n",
    "    next_url = '' + next_url\n",
    "    \n",
    "    \n",
    "    return next_url\n",
    "    \n",
    "\n",
    "\n",
    "soup = shelfy.models.scraper.get_page_soup(url)\n",
    "print(get_next_sales_url_from_amazon(soup))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "response = amazon.ItemLookup(ItemId=\"0553582011\", ResponseGroup=\"Offers\",\n",
    "    SearchIndex=\"Books\", IdType=\"ISBN\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "soup = BeautifulSoup(response, 'lxml')\n",
    "\n",
    "print(soup.lowestnewprice.amount.contents[0])\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "ua = {'User-Agent': 'Mozilla/5.0 (Macintosh; Intel Mac OS X 10_8_2) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/27.0.1453.116 Safari/537.36'}\n",
    "\n",
    "\n",
    "rest_url = 'http://iopscience.iop.org/article/10.1086/522291/fulltext/'\n",
    "\n",
    "response = requests.get(rest_url, headers=ua)\n",
    "\n",
    "soup = BeautifulSoup(response.content, 'html.parser')\n",
    "\n",
    "print(soup)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
